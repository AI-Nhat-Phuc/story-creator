# GPT Integration Guide - Story Creator

## T·ªïng Quan

Story Creator t√≠ch h·ª£p OpenAI GPT-4o-mini ƒë·ªÉ:
1. ü§ñ **Character Simulation**: AI quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông nh√¢n v·∫≠t
2. üåç **World Analysis**: Ph√¢n t√≠ch m√¥ t·∫£ th·∫ø gi·ªõi, t·∫°o entities/locations
3. üìñ **Story Enhancement**: T·∫°o m√¥ t·∫£ c√¢u chuy·ªán phong ph√∫
4. üåê **Translation**: D·ªãch English ‚Üí Vietnamese (simulation mode)

## Environment Setup

### 1. L·∫•y API Key

1. Truy c·∫≠p [OpenAI Platform](https://platform.openai.com/)
2. ƒêƒÉng nh·∫≠p/ƒêƒÉng k√Ω account
3. V√†o **API Keys** section
4. Click **"Create new secret key"**
5. Copy key (ch·ªâ hi·ªÉn th·ªã 1 l·∫ßn!)

### 2. T·∫°o File `.env`

```bash
# T·∫°o file .env trong th∆∞ m·ª•c root
# c:\Users\PhucPN\OneDrive\Desktop\AI\Ideas\story-creator\.env
```

**N·ªôi dung**:
```env
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

**‚ö†Ô∏è L∆∞u √Ω**:
- ‚ùå KH√îNG commit file `.env` l√™n Git
- ‚úÖ File `.env` ƒë√£ ƒë∆∞·ª£c th√™m v√†o `.gitignore`
- ‚úÖ API key b·∫Øt ƒë·∫ßu b·∫±ng `sk-proj-` ho·∫∑c `sk-`

### 3. C√†i ƒê·∫∑t Dependencies

```bash
pip install openai>=1.0.0
pip install python-dotenv>=0.19.0
```

### 4. Test API Key

```bash
# Ki·ªÉm tra API key c√≥ ho·∫°t ƒë·ªông
python test_api_key.py
```

**Expected Output**:
```
‚úÖ API Key h·ª£p l·ªá
üìä Model: gpt-4o-mini
üí∞ Quota available
```

## GPT Client Architecture

### File Structure
```
ai/
  ‚îú‚îÄ‚îÄ __init__.py
  ‚îú‚îÄ‚îÄ gpt_client.py           # Low-level GPT API wrapper
  ‚îú‚îÄ‚îÄ prompts.py              # Prompt templates
  ‚îî‚îÄ‚îÄ simulation.py           # Simulation logic

services/
  ‚îî‚îÄ‚îÄ gpt_service.py          # High-level service layer (RECOMMENDED)
```

## GPT Client (`ai/gpt_client.py`)

### Initialization

```python
from ai.gpt_client import GPTIntegration

# Auto-load API key t·ª´ .env
gpt = GPTIntegration()

# Check availability
if gpt.is_available():
    print("‚úÖ GPT ready")
else:
    print("‚ùå GPT not available")
```

**What Happens**:
1. Load `OPENAI_API_KEY` t·ª´ `.env` (via `python-dotenv`)
2. Initialize OpenAI client
3. Set model = `gpt-4o-mini`
4. Validate API key

### Model Configuration

**Current Model**: `gpt-4o-mini`

**Why not gpt-4-turbo or gpt-5-nano**:
- ‚ùå `gpt-5-nano`: C√≥ reasoning tokens issue
- ‚úÖ `gpt-4o-mini`: Stable, fast, cost-effective
- ‚ö° Response time: ~2-5 seconds
- üí∞ Cost: $0.00015/1K input tokens, $0.0006/1K output tokens

**API Parameters**:
```python
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[...],
    max_completion_tokens=1000,  # ‚ùó NOT max_tokens
    # temperature=1.0,            # ‚ùó NOT supported
)
```

### Core Methods

#### 1. Character Decision Making

```python
decision = gpt.generate_character_decision(
    character_name="Arthur",
    situation="You see a dragon approaching the village",
    story_context="Medieval fantasy world, you are a knight",
    character_traits="Brave, loyal, skilled with sword"
)

print(decision)
# Output: "I draw my sword and stand between the dragon and the village"
```

**Prompt Template** (trong `ai/prompts.py`):
```python
CHARACTER_DECISION_PROMPT = """
You are {character_name} with these traits: {character_traits}.

Current situation: {situation}

Story context: {story_context}

What do you do? Respond in first person, in one clear sentence.
"""
```

#### 2. Translation (Vietnamese)

```python
vietnamese_text = gpt.translate_eng_to_vn(
    "The hero bravely faces the dragon"
)

print(vietnamese_text)
# Output: "Ng∆∞·ªùi anh h√πng d≈©ng c·∫£m ƒë·ªëi m·∫∑t v·ªõi con r·ªìng"
```

**Use Case**: Simulation mode - d·ªãch GPT responses sang ti·∫øng Vi·ªát

#### 3. World Description Analysis (Raw)

```python
analysis = gpt.generate_world_description(
    world_type="fantasy",
    description="A kingdom with magic and dragons"
)

# Returns JSON string v·ªõi entities v√† locations
```

**‚ö†Ô∏è Recommended**: D√πng `GPTService` thay v√¨ g·ªçi tr·ª±c ti·∫øp

## GPT Service (`services/gpt_service.py`)

### Why Use Service Layer?

‚úÖ **Async execution** v·ªõi threading
‚úÖ **Callback pattern** cho UI updates
‚úÖ **Error handling** t·∫≠p trung
‚úÖ **Business logic separation** t·ª´ GPT client

### Initialization

```python
from services import GPTService
from ai.gpt_client import GPTIntegration

gpt = GPTIntegration()
gpt_service = GPTService(gpt)

# Check availability
if gpt_service.is_available():
    print("‚úÖ Service ready")
```

### World Description Generation

```python
def on_success(result):
    """Callback khi GPT ho√†n th√†nh"""
    print("‚úÖ Entities:", result['entities'])
    print("‚úÖ Locations:", result['locations'])

def on_error(error_message):
    """Callback khi c√≥ l·ªói"""
    print("‚ùå Error:", error_message)

# G·ªçi async
gpt_service.generate_world_description(
    world_type="fantasy",
    callback_success=on_success,
    callback_error=on_error
)

# Code ti·∫øp t·ª•c ch·∫°y, kh√¥ng block
print("‚è≥ GPT ƒëang x·ª≠ l√Ω...")
```

**Result Format**:
```json
{
  "entities": [
    {
      "name": "King Arthur",
      "entity_type": "ruler",
      "description": "Noble king of Camelot",
      "attributes": {
        "Strength": 7,
        "Intelligence": 8,
        "Charisma": 9
      }
    }
  ],
  "locations": [
    {
      "name": "Camelot Castle",
      "description": "Majestic fortress",
      "coordinates": {"x": 0, "y": 0}
    }
  ]
}
```

### Story Description Generation

```python
gpt_service.generate_story_description(
    genre="adventure",
    world_context="Fantasy world with magic",
    character_names=["Arthur", "Merlin"],
    callback_success=on_success,
    callback_error=on_error
)
```

### Analyze World Entities (Web Interface)

```python
gpt_service.analyze_world_entities(
    world_description="A medieval kingdom with dragons and magic",
    world_type="fantasy",
    callback_success=on_success,
    callback_error=on_error
)
```

**Async Workflow**:
1. Client t·∫°o unique `task_id`
2. Call service v·ªõi callbacks l∆∞u v√†o session storage
3. Service ch·∫°y GPT trong background thread
4. Client poll results t·ª´ session storage

## Web Interface Integration

### Task-Based GPT Calls

**Backend** (`interfaces/web_interface.py`):
```python
@self.app.route('/api/gpt/analyze', methods=['POST'])
def analyze_gpt():
    data = request.json
    task_id = str(uuid.uuid4())

    def on_success(result):
        self.gpt_results[task_id] = {
            'status': 'completed',
            'result': result
        }

    def on_error(error):
        self.gpt_results[task_id] = {
            'status': 'error',
            'error': str(error)
        }

    # Initialize pending status
    self.gpt_results[task_id] = {'status': 'pending'}

    # Start async GPT call
    self.gpt_service.analyze_world_entities(
        world_description=data['world_description'],
        world_type=data['world_type'],
        callback_success=on_success,
        callback_error=on_error
    )

    return jsonify({'task_id': task_id})

@self.app.route('/api/gpt/results/<task_id>')
def get_gpt_results(task_id):
    result = self.gpt_results.get(task_id, {'status': 'not_found'})
    return jsonify(result)
```

**Frontend** (`static/js/app.js`):
```javascript
async function analyzeWorldWithGPT() {
    const description = document.getElementById('worldDescription').value;
    const worldType = document.getElementById('worldType').value;

    // Start analysis
    const response = await fetch('/api/gpt/analyze', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
            world_description: description,
            world_type: worldType
        })
    });

    const { task_id } = await response.json();

    // Poll for results
    pollGPTResults(task_id);
}

function pollGPTResults(taskId) {
    const interval = setInterval(async () => {
        const response = await fetch(`/api/gpt/results/${taskId}`);
        const data = await response.json();

        if (data.status === 'completed') {
            clearInterval(interval);
            // Use data.result
            console.log('‚úÖ GPT completed:', data.result);
        } else if (data.status === 'error') {
            clearInterval(interval);
            console.error('‚ùå GPT error:', data.error);
        }
        // else: still pending, continue polling
    }, 500); // Poll every 500ms
}
```

## Simulation Mode Integration

### Character Simulation Flow

```python
from interfaces import SimulationInterface

sim = SimulationInterface(storage_type="nosql")
sim.run()
```

**User Flow**:
1. User ch·ªçn world
2. User ch·ªçn character ƒë·ªÉ control
3. T·∫°i m·ªói time_index:
   - ƒê·ªçc story content
   - GPT t·∫°o situation t·ª´ story
   - User nh·∫≠n 3 choices: A (action), B (opposite), C (abandon)
   - User ch·ªçn ‚Üí L∆∞u decision
4. C√°c nh√¢n v·∫≠t kh√°c ‚Üí GPT t·ª± ƒë·ªông ch·ªçn
5. Ti·∫øn ƒë·∫øn time_index ti·∫øp theo

### GPT Decision Making

```python
# Trong simulation_interface.py
decision = self.gpt.generate_character_decision(
    character_name=character.name,
    situation=current_situation,
    story_context=world.description,
    character_traits=f"{character.entity_type}, {character.description}"
)

# Translation (n·∫øu b·∫≠t)
if enable_translation:
    decision_vn = self.gpt.translate_eng_to_vn(decision)
```

## Prompt Engineering

### Best Practices

1. **Be Specific**: Cung c·∫•p ƒë·ªß context
2. **Format Clear**: Y√™u c·∫ßu JSON format khi c·∫ßn
3. **Limit Scope**: Gi·ªõi h·∫°n response length
4. **Examples**: Cho examples trong prompt

### Prompt Templates (`ai/prompts.py`)

```python
WORLD_ANALYSIS_PROMPT = """
Analyze this {world_type} world description and extract entities and locations.

Description: {description}

Return a JSON object with:
{{
  "entities": [
    {{
      "name": "character name",
      "entity_type": "warrior/mage/ruler/merchant/etc",
      "description": "brief description",
      "attributes": {{"Strength": 0-10, "Intelligence": 0-10, "Charisma": 0-10}}
    }}
  ],
  "locations": [
    {{
      "name": "location name",
      "description": "brief description"
    }}
  ]
}}

Extract 3-5 entities and 2-4 locations.
"""
```

## Error Handling

### Common Errors

#### 1. API Key Invalid
```python
try:
    gpt = GPTIntegration()
except ValueError as e:
    print(f"‚ùå API Key error: {e}")
    # H∆∞·ªõng d·∫´n user check .env file
```

#### 2. Rate Limit
```python
try:
    response = gpt.generate_character_decision(...)
except Exception as e:
    if "rate_limit" in str(e).lower():
        print("‚è≥ Rate limit reached, please wait")
    else:
        print(f"‚ùå Error: {e}")
```

#### 3. Network Error
```python
try:
    response = gpt.generate_world_description(...)
except Exception as e:
    print("üåê Network error, check connection")
```

### Graceful Degradation

```python
# Check GPT availability tr∆∞·ªõc khi s·ª≠ d·ª•ng
if self.has_gpt:
    # Use GPT features
    decision = self.gpt.generate_character_decision(...)
else:
    # Fallback: Random choice ho·∫∑c disable feature
    decision = random.choice(["Option A", "Option B"])
    print("‚ö†Ô∏è GPT not available, using fallback")
```

## Cost Management

### Token Usage

**Estimate**:
- World analysis: ~500 input + ~800 output = ~1300 tokens
- Character decision: ~200 input + ~100 output = ~300 tokens
- Translation: ~100 input + ~120 output = ~220 tokens

**Cost per Operation** (gpt-4o-mini):
- World analysis: $0.00075 + $0.00048 = **$0.00123**
- Character decision: $0.00003 + $0.00006 = **$0.00009**
- Translation: $0.000015 + $0.000072 = **$0.000087**

**Monthly Budget Example**:
- 1000 world analyses: $1.23
- 10,000 character decisions: $0.90
- 5,000 translations: $0.44
- **Total**: ~$2.60/month

### Optimization Tips

1. ‚úÖ **Cache results**: L∆∞u GPT responses v√†o database
2. ‚úÖ **Batch requests**: G·ªôp multiple operations n·∫øu ƒë∆∞·ª£c
3. ‚úÖ **Limit max_tokens**: Set reasonable limits
4. ‚úÖ **Use callbacks**: Avoid retry loops

## Testing

### Unit Tests

```python
# test_gpt.py
import unittest
from ai.gpt_client import GPTIntegration

class TestGPT(unittest.TestCase):
    def setUp(self):
        self.gpt = GPTIntegration()

    def test_availability(self):
        self.assertTrue(self.gpt.is_available())

    def test_character_decision(self):
        decision = self.gpt.generate_character_decision(
            character_name="Test Hero",
            situation="Test situation",
            story_context="Test context",
            character_traits="Brave"
        )
        self.assertIsInstance(decision, str)
        self.assertGreater(len(decision), 0)
```

### Integration Tests

```bash
# Test v·ªõi real API
python test_api_key.py

# Test simulation mode
python demo_gpt_simulation.py
```

## Security Best Practices

1. üîí **Never commit API keys**: Use `.env` file
2. üîí **Rotate keys regularly**: Generate new keys every 90 days
3. üîí **Monitor usage**: Check OpenAI dashboard cho unusual activity
4. üîí **Limit permissions**: Use restricted API keys n·∫øu c√≥ option
5. üîí **Log cautiously**: ƒê·ª´ng log API keys ho·∫∑c sensitive prompts

## Troubleshooting

### GPT Not Working

```bash
# 1. Check .env file exists
dir .env

# 2. Check API key format
type .env

# 3. Test API key
python test_api_key.py

# 4. Check internet connection
ping api.openai.com

# 5. Check Python version
python --version  # Should be 3.7+

# 6. Reinstall packages
pip install --upgrade openai python-dotenv
```

### Common Issues

| Issue | Solution |
|-------|----------|
| `No API key found` | T·∫°o file `.env` v·ªõi `OPENAI_API_KEY=...` |
| `Rate limit exceeded` | ƒê·ª£i 1 ph√∫t ho·∫∑c upgrade plan |
| `Invalid request` | Check prompt format, max_tokens |
| `Timeout` | Increase timeout ho·∫∑c retry |

## Next Steps

1. üìñ ƒê·ªçc [OpenAI API Documentation](https://platform.openai.com/docs)
2. üß™ Test v·ªõi `test_api_key.py` v√† `demo_gpt_simulation.py`
3. üéÆ Th·ª≠ Simulation Mode ƒë·ªÉ hi·ªÉu GPT workflow
4. üîß Customize prompts trong `ai/prompts.py`
